name: Validate Azure¬†OpenAI response

on:
  workflow_dispatch:        # run on demand from the Actions tab

jobs:
  run-validation:
    runs-on: ubuntu-latest
    environment: responses   # üîë unlocks the environment‚Äëscoped secrets

    # Expose the environment secrets as real process env‚Äëvars
    env:
      AZURE_OPENAI_API_KEY:       ${{ secrets.AZURE_OPENAI_API_KEY }}
      AZURE_OPENAI_V1_API_ENDPOINT: ${{ secrets.AZURE_OPENAI_V1_API_ENDPOINT }}
      AZURE_OPENAI_API_MODEL:     ${{ secrets.AZURE_OPENAI_API_MODEL }}

    steps:
    # 1¬†‚Äì check out the repo so the script is available
    - uses: actions/checkout@v4

    # 2¬†‚Äì set up Python
    - uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    # 3¬†‚Äì install the script‚Äôs two lightweight deps
    - name: Install requirements
      run: |
        python -m pip install --upgrade pip
        pip install openai python-dotenv

    # 4¬†‚Äì run the script, grade the result, assemble a report
    - name: Execute script and capture outcome
      id: test
      shell: bash
      run: |
        set +e                                 # we want to handle failures ourselves
        TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

        # === run the user script ===
        python responses-basic-aoai-v1.py > out.txt 2>&1
        EXIT_CODE=$?

        # === decide pass / fail ===
        if [[ $EXIT_CODE -eq 0 && -s out.txt ]]; then
          PASS_FAIL="PASS"
        else
          PASS_FAIL="FAIL"
        fi

        # === build JSON report ===
        jq -n \
          --arg date        "$TIMESTAMP" \
          --arg output      "$(cat out.txt | tr -d '\r')" \
          --arg pass_fail   "$PASS_FAIL" \
          --argjson code    "$EXIT_CODE" \
          '{test_run_date: $date,
            output:        $output,
            pass_fail:     $pass_fail,
            error_code:    $code}' > aoai-test-result.json

    # 5¬†‚Äì make the report downloadable from the run summary
    - name: Upload result artifact
      uses: actions/upload-artifact@v4
      with:
        name: aoai-response-test         # folder name visible in the UI
        path: aoai-test-result.json

    # 6 ‚Äì parse JSON and inject into README
    - name: Parse results and update README
      shell: bash
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # read the values
        PASS=$(jq -r .pass_fail aoai-test-result.json)
        CODE=$(jq -r .error_code aoai-test-result.json)
        DATE=$(jq -r .test_run_date aoai-test-result.json)

        # build the markdown snippet
        read -r -d '' SNIPPET << EOF
        <!-- AOAI-RESULTS-START -->
        ## ‚öôÔ∏è Last Azure OpenAI Test
        - **Date:** $DATE
        - **Result:** $PASS
        - **Exit code:** $CODE
        <!-- AOAI-RESULTS-END -->
        EOF

        # replace the section between the markers in README.md
        # (assumes README.md already has those two markers somewhere)
        awk -v new="$SNIPPET" '
          /<!-- AOAI-RESULTS-START -->/ { print new; skip=1; next }
          /<!-- AOAI-RESULTS-END -->/   { print; skip=0; next }
          skip { next }
          { print }
        ' README.md > README.tmp && mv README.tmp README.md

    # 7 ‚Äì commit & push the updated README back
    - name: Commit updated README
      uses: stefanzweifel/git-auto-commit-action@v4
      with:
        commit_message: chore: update README with latest AOAI test results
        file_pattern: README.md
        author_name: GitHub Actions
        author_email: actions@github.com
        branch: ${{ github.ref_name }}
